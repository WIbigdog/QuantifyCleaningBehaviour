{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd33d93",
   "metadata": {},
   "source": [
    "# Information\n",
    "\n",
    "## CC2CAll_min_mrg \n",
    "\n",
    "This code uses:\n",
    "+ Cleaner_Centroid with 2 points\n",
    "+ Then uses the centroid to compare distance between all points, and calculates the distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b7edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats  # For mode calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecd6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_interactions(distances, min_consecutive=60, threshold=250, margin=30):\n",
    "    \"\"\"\n",
    "    Detect interactions in a sequence of distances.\n",
    "\n",
    "    Parameters:\n",
    "        distances (list or numpy array): A sequence of distances.\n",
    "        min_consecutive (int): Minimum consecutive frames required for an interaction.\n",
    "        threshold (float): Threshold value to determine an interaction.\n",
    "        margin (int): Number of frames where the rules don't apply and gaps can be merged.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples where each tuple represents an interaction (start_frame, end_frame).\n",
    "    \"\"\"\n",
    "    interactions = []\n",
    "    current_start = None\n",
    "    last_interaction_end = None  # Keep track of the end frame of the last interaction\n",
    "\n",
    "    for i, distance in enumerate(distances):\n",
    "        if distance < threshold:\n",
    "            if current_start is None:\n",
    "                current_start = i\n",
    "        else:\n",
    "            if current_start is not None:\n",
    "                if i - current_start >= min_consecutive:\n",
    "                    # Check if there is a margin to merge nearby interactions\n",
    "                    if last_interaction_end is not None and current_start - last_interaction_end <= margin:\n",
    "                        interactions[-1] = (interactions[-1][0], i - 1)\n",
    "                    else:\n",
    "                        interactions.append((current_start, i - 1))\n",
    "                    last_interaction_end = i - 1\n",
    "                current_start = None\n",
    "\n",
    "    # Check if an interaction is ongoing at the end of the sequence\n",
    "    if current_start is not None and len(distances) - current_start >= min_consecutive:\n",
    "        interactions.append((current_start, len(distances) - 1))\n",
    "\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc496ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r\"C:\\Users\\raulo\\Desktop\\ze_vids\\phase_3\\Tracks+Label_Top&Bot\"\n",
    "files = os.listdir(directory)\n",
    "\n",
    "result_dataframes = {}\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(directory, file))\n",
    "    \n",
    "    df[\"Behavior\"].replace({\"TS\": \"interaction\", \"jolts\": \"interaction\"}, inplace=True)\n",
    "    # Create a new DataFrame to store the results\n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    # Add relevant data to the new DataFrame\n",
    "    new_df[\"Behavior\"] = df['Behavior']\n",
    "\n",
    "    new_df['Client_Mouth_X_top'] = df['Client_Mouth']\n",
    "    new_df['Client_Mouth_Y_top'] = df['Client_Mouth.1']\n",
    "    new_df['Client_Mouth_Z_front']= df['Client_Mouth_Front.1']\n",
    "\n",
    "    new_df['Client_S1_X_top'] = df['Client_Spine_1']\n",
    "    new_df['Client_S1_Y_top'] = df['Client_Spine_1.1']\n",
    "    new_df['Client_S1_Z_front']= df['Client_Spine_head_Front.1']\n",
    "    \n",
    "    new_df['Client_STop1_X_top'] = df['Client_Spine_1']\n",
    "    new_df['Client_STop1_Y_top'] = df['Client_Spine_1.1']\n",
    "    new_df['Client_STop1_Z_front']= df['Client_Body_top1_Front.1']\n",
    "    \n",
    "    new_df['Client_SBot1_X_top'] = df['Client_Spine_1']\n",
    "    new_df['Client_SBot1_Y_top'] = df['Client_Spine_1.1']\n",
    "    new_df['Client_SBot1_Z_front']= df['Client_Body_bot1_Front.1']\n",
    "\n",
    "    new_df['Client_S2_X_top'] = df['Client_Spine_2']\n",
    "    new_df['Client_S2_Y_top'] = df['Client_Spine_2.1']\n",
    "    new_df['Client_S2_Z_front']= df['Client_Spine_mid_Front.1']\n",
    "    \n",
    "    new_df['Client_STop2_X_top'] = df['Client_Spine_2']\n",
    "    new_df['Client_STop2_Y_top'] = df['Client_Spine_2.1']\n",
    "    new_df['Client_STop2_Z_front']= df['Client_Body_top2_Front.1']\n",
    "    \n",
    "    new_df['Client_SBot2_X_top'] = df['Client_Spine_2']\n",
    "    new_df['Client_SBot2_Y_top'] = df['Client_Spine_2.1']\n",
    "    new_df['Client_SBot2_Z_front']= df['Client_Body_bot2_Front.1']\n",
    "    \n",
    "    new_df['Client_Tail_X_top'] = df['Client_Tail']\n",
    "    new_df['Client_Tail_Y_top'] = df['Client_Tail.1']\n",
    "    new_df['Client_Tail_Z_front']= df['Client_Tail_Front.1']\n",
    "    \n",
    "    new_df['Client_TailTipTop_X_top'] = df['Client_TailTip']\n",
    "    new_df['Client_TailTipTop_Y_top'] = df['Client_TailTip.1']\n",
    "    new_df['Client_TailTipTop_Z_front']= df['Client_Tail_Top_Front.1']\n",
    "\n",
    "    new_df['Client_TailTipBot_X_top'] = df['Client_TailTip']\n",
    "    new_df['Client_TailTipBot_Y_top'] = df['Client_TailTip.1']\n",
    "    new_df['Client_TailTipBot_Z_front']= df['Client_Tail_Bot_Front.1']\n",
    "\n",
    "    \n",
    "    \n",
    "    new_df['Cleaner_Mouth_X_top'] = df['Cleaner_Mouth']\n",
    "    new_df['Cleaner_Mouth_Y_top'] = df['Cleaner_Mouth.1']\n",
    "    new_df['Cleaner_Mouth_Z_front']= df['Cleaner_Mouth_Front.1']\n",
    "\n",
    "    new_df['Cleaner_Spine1_X_top'] = df['Cleaner_Spine1']\n",
    "    new_df['Cleaner_Spine1_Y_top'] = df['Cleaner_Spine1.1']\n",
    "    new_df['Cleaner_Spine1_Z_front']= df['Cleaner_Spine1_Front.1']\n",
    "\n",
    "    \n",
    "\n",
    "    new_df[\"Frame\"] = df['Frame']\n",
    "    \n",
    "    # Create a new column in new_df to store the centroid of the cleaner fish for each row\n",
    "    new_df['Cleaner_Centroid_X'] = new_df[['Cleaner_Mouth_X_top', 'Cleaner_Spine1_X_top']].mean(axis=1)\n",
    "    new_df['Cleaner_Centroid_Y'] = new_df[['Cleaner_Mouth_Y_top', 'Cleaner_Spine1_Y_top']].mean(axis=1)\n",
    "    new_df['Cleaner_Centroid_Z'] = new_df[['Cleaner_Mouth_Z_front', 'Cleaner_Spine1_Z_front']].mean(axis=1)\n",
    "\n",
    "    # Initialize a column to store the smallest distance for each row\n",
    "    new_df['Min_Distance'] = np.inf  # Initialize with infinity\n",
    "\n",
    "    # Loop through client points and calculate distance, updating 'Min_Distance' if a smaller distance is found\n",
    "    for client_point in ['Client_Mouth', 'Client_S1', 'Client_STop1', 'Client_SBot1', \n",
    "                         'Client_S2', 'Client_STop2', 'Client_SBot2', 'Client_Tail', 'Client_TailTipTop', 'Client_TailTipBot']:\n",
    "        client_x = new_df[f'{client_point}_X_top']\n",
    "        client_y = new_df[f'{client_point}_Y_top']\n",
    "        client_z = new_df[f'{client_point}_Z_front']\n",
    "\n",
    "        distance = np.sqrt(\n",
    "            (client_x - new_df['Cleaner_Centroid_X'])**2 +\n",
    "            (client_y - new_df['Cleaner_Centroid_Y'])**2 +\n",
    "            (client_z - new_df['Cleaner_Centroid_Z'])**2\n",
    "        )\n",
    "\n",
    "        new_df['Min_Distance'] = np.minimum(new_df['Min_Distance'], distance)\n",
    "    \n",
    "    new_df[\"Interaction_Predictions\"] = \"background\"  # Initialization of predictions\n",
    "\n",
    "    result_dataframes[file.split(\"_\")[0]] = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a4725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raulo\\AppData\\Local\\Temp\\ipykernel_9400\\828851113.py:20: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode_value = stats.mode(selected_data).mode[0]\n",
      "C:\\Users\\raulo\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py:110: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  warnings.warn(\"The input array could not be properly \"\n",
      "C:\\Users\\raulo\\AppData\\Local\\Temp\\ipykernel_9400\\828851113.py:20: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  mode_value = stats.mode(selected_data).mode[0]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store summary values for each DataFrame\n",
    "summary_values = {}\n",
    "\n",
    "for data_frame in result_dataframes:\n",
    "    total_frames = 0\n",
    "    correctly_detected_event = 0\n",
    "    total = 0\n",
    "    correctly_frame_count = 0\n",
    "\n",
    "    interactions = detect_interactions(result_dataframes[data_frame][\"Min_Distance\"])\n",
    "\n",
    "    for interaction in interactions:\n",
    "\n",
    "        start_frame, end_frame = interaction\n",
    "\n",
    "        if end_frame - start_frame + 1 >= 15:\n",
    "            total += 1  # Increment the total count for eligible interactions\n",
    "            total_frames += end_frame - start_frame + 1\n",
    "            selected_data = result_dataframes[data_frame].loc[start_frame:end_frame, \"Behavior\"]\n",
    "            mode_value = stats.mode(selected_data).mode[0]\n",
    "\n",
    "            if mode_value == \"interaction\" or mode_value == \"TS\":\n",
    "                correctly_detected_event +=1\n",
    "                correctly_frame_count += end_frame - start_frame + 1\n",
    "\n",
    "            # Store the prediction in the new column\n",
    "            result_dataframes[data_frame].loc[start_frame:end_frame, \"Interaction_Predictions\"] = mode_value\n",
    "                  \n",
    "            # Store the summary values in the summary_values dictionary\n",
    "            summary_values[data_frame] = {\n",
    "            \"total_frames\": total_frames,\n",
    "            \"correctly_detected_event\": correctly_detected_event,\n",
    "            \"total\": total,\n",
    "            \"correctly_frame_count\": correctly_frame_count\n",
    "            }\n",
    "            \n",
    "#             if total == 1:\n",
    "#                 print(f\"\\nData from: {data_frame}\")            \n",
    "#             print(f\"Interaction detected from frame {start_frame} to {end_frame} (Duration: {end_frame - start_frame + 1} frames) with a true Behavior of {mode_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33bc787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from: LD03 with threshold of: 100 and min_consecutives of: 30\n",
      "This data has 69 true events\n",
      "There were 5281 frames correctly classified, out of a total of 5976 frames classified as interaction.\n",
      "This results in an accuracy of 88.37%.\n",
      "There were a total of 56 events detected correctly, out of 68 total events detected. (82.35%)\n",
      "There was 81.16% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 100 and min_consecutives of: 30\n",
      "This data has 63 true events\n",
      "There were 7625 frames correctly classified, out of a total of 8579 frames classified as interaction.\n",
      "This results in an accuracy of 88.88%.\n",
      "There were a total of 65 events detected correctly, out of 82 total events detected. (79.27%)\n",
      "There was 103.17% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 100 and min_consecutives of: 30\n",
      "This data has 81 true events\n",
      "There were 3849 frames correctly classified, out of a total of 5121 frames classified as interaction.\n",
      "This results in an accuracy of 75.16%.\n",
      "There were a total of 62 events detected correctly, out of 90 total events detected. (68.89%)\n",
      "There was 76.54% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 100 and min_consecutives of: 30\n",
      "This data has 34 true events\n",
      "There were 1397 frames correctly classified, out of a total of 1437 frames classified as interaction.\n",
      "This results in an accuracy of 97.22%.\n",
      "There were a total of 15 events detected correctly, out of 16 total events detected. (93.75%)\n",
      "There was 44.12% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 100 and min_consecutives of: 30\n",
      "This data has 30 true events\n",
      "There were 4668 frames correctly classified, out of a total of 5835 frames classified as interaction.\n",
      "This results in an accuracy of 80.00%.\n",
      "There were a total of 35 events detected correctly, out of 50 total events detected. (70.00%)\n",
      "There was 116.67% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 100 and min_consecutives of: 30\n",
      "This data has 50 true events\n",
      "There were 3669 frames correctly classified, out of a total of 4177 frames classified as interaction.\n",
      "This results in an accuracy of 87.84%.\n",
      "There were a total of 44 events detected correctly, out of 57 total events detected. (77.19%)\n",
      "There was 88.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 100 and min_consecutives of: 45\n",
      "This data has 69 true events\n",
      "There were 4492 frames correctly classified, out of a total of 5026 frames classified as interaction.\n",
      "This results in an accuracy of 89.38%.\n",
      "There were a total of 40 events detected correctly, out of 48 total events detected. (83.33%)\n",
      "There was 57.97% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 100 and min_consecutives of: 45\n",
      "This data has 63 true events\n",
      "There were 7001 frames correctly classified, out of a total of 7751 frames classified as interaction.\n",
      "This results in an accuracy of 90.32%.\n",
      "There were a total of 55 events detected correctly, out of 66 total events detected. (83.33%)\n",
      "There was 87.30% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 100 and min_consecutives of: 45\n",
      "This data has 81 true events\n",
      "There were 2388 frames correctly classified, out of a total of 2909 frames classified as interaction.\n",
      "This results in an accuracy of 82.09%.\n",
      "There were a total of 34 events detected correctly, out of 43 total events detected. (79.07%)\n",
      "There was 41.98% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 100 and min_consecutives of: 45\n",
      "This data has 34 true events\n",
      "There were 1218 frames correctly classified, out of a total of 1218 frames classified as interaction.\n",
      "This results in an accuracy of 100.00%.\n",
      "There were a total of 10 events detected correctly, out of 10 total events detected. (100.00%)\n",
      "There was 29.41% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 100 and min_consecutives of: 45\n",
      "This data has 30 true events\n",
      "There were 4186 frames correctly classified, out of a total of 5148 frames classified as interaction.\n",
      "This results in an accuracy of 81.31%.\n",
      "There were a total of 30 events detected correctly, out of 40 total events detected. (75.00%)\n",
      "There was 100.00% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 100 and min_consecutives of: 45\n",
      "This data has 50 true events\n",
      "There were 3102 frames correctly classified, out of a total of 3218 frames classified as interaction.\n",
      "This results in an accuracy of 96.40%.\n",
      "There were a total of 32 events detected correctly, out of 34 total events detected. (94.12%)\n",
      "There was 64.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 100 and min_consecutives of: 60\n",
      "This data has 69 true events\n",
      "There were 3745 frames correctly classified, out of a total of 4081 frames classified as interaction.\n",
      "This results in an accuracy of 91.77%.\n",
      "There were a total of 29 events detected correctly, out of 33 total events detected. (87.88%)\n",
      "There was 42.03% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 100 and min_consecutives of: 60\n",
      "This data has 63 true events\n",
      "There were 6069 frames correctly classified, out of a total of 6603 frames classified as interaction.\n",
      "This results in an accuracy of 91.91%.\n",
      "There were a total of 38 events detected correctly, out of 45 total events detected. (84.44%)\n",
      "There was 60.32% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 100 and min_consecutives of: 60\n",
      "This data has 81 true events\n",
      "There were 1533 frames correctly classified, out of a total of 1814 frames classified as interaction.\n",
      "This results in an accuracy of 84.51%.\n",
      "There were a total of 18 events detected correctly, out of 22 total events detected. (81.82%)\n",
      "There was 22.22% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 100 and min_consecutives of: 60\n",
      "This data has 34 true events\n",
      "There were 1061 frames correctly classified, out of a total of 1061 frames classified as interaction.\n",
      "This results in an accuracy of 100.00%.\n",
      "There were a total of 7 events detected correctly, out of 7 total events detected. (100.00%)\n",
      "There was 20.59% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 100 and min_consecutives of: 60\n",
      "This data has 30 true events\n",
      "There were 3425 frames correctly classified, out of a total of 4217 frames classified as interaction.\n",
      "This results in an accuracy of 81.22%.\n",
      "There were a total of 22 events detected correctly, out of 29 total events detected. (75.86%)\n",
      "There was 73.33% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 100 and min_consecutives of: 60\n",
      "This data has 50 true events\n",
      "There were 2776 frames correctly classified, out of a total of 2847 frames classified as interaction.\n",
      "This results in an accuracy of 97.51%.\n",
      "There were a total of 26 events detected correctly, out of 27 total events detected. (96.30%)\n",
      "There was 52.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 125 and min_consecutives of: 30\n",
      "This data has 69 true events\n",
      "There were 7251 frames correctly classified, out of a total of 8444 frames classified as interaction.\n",
      "This results in an accuracy of 85.87%.\n",
      "There were a total of 64 events detected correctly, out of 85 total events detected. (75.29%)\n",
      "There was 92.75% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 125 and min_consecutives of: 30\n",
      "This data has 63 true events\n",
      "There were 9030 frames correctly classified, out of a total of 10419 frames classified as interaction.\n",
      "This results in an accuracy of 86.67%.\n",
      "There were a total of 67 events detected correctly, out of 94 total events detected. (71.28%)\n",
      "There was 106.35% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 125 and min_consecutives of: 30\n",
      "This data has 81 true events\n",
      "There were 6626 frames correctly classified, out of a total of 9696 frames classified as interaction.\n",
      "This results in an accuracy of 68.34%.\n",
      "There were a total of 87 events detected correctly, out of 149 total events detected. (58.39%)\n",
      "There was 107.41% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 125 and min_consecutives of: 30\n",
      "This data has 34 true events\n",
      "There were 2196 frames correctly classified, out of a total of 2325 frames classified as interaction.\n",
      "This results in an accuracy of 94.45%.\n",
      "There were a total of 19 events detected correctly, out of 22 total events detected. (86.36%)\n",
      "There was 55.88% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 125 and min_consecutives of: 30\n",
      "This data has 30 true events\n",
      "There were 5713 frames correctly classified, out of a total of 7713 frames classified as interaction.\n",
      "This results in an accuracy of 74.07%.\n",
      "There were a total of 29 events detected correctly, out of 49 total events detected. (59.18%)\n",
      "There was 96.67% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 125 and min_consecutives of: 30\n",
      "This data has 50 true events\n",
      "There were 5164 frames correctly classified, out of a total of 6431 frames classified as interaction.\n",
      "This results in an accuracy of 80.30%.\n",
      "There were a total of 50 events detected correctly, out of 77 total events detected. (64.94%)\n",
      "There was 100.00% events detected\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from: LD03 with threshold of: 125 and min_consecutives of: 45\n",
      "This data has 69 true events\n",
      "There were 6708 frames correctly classified, out of a total of 7441 frames classified as interaction.\n",
      "This results in an accuracy of 90.15%.\n",
      "There were a total of 55 events detected correctly, out of 65 total events detected. (84.62%)\n",
      "There was 79.71% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 125 and min_consecutives of: 45\n",
      "This data has 63 true events\n",
      "There were 8500 frames correctly classified, out of a total of 9335 frames classified as interaction.\n",
      "This results in an accuracy of 91.06%.\n",
      "There were a total of 61 events detected correctly, out of 72 total events detected. (84.72%)\n",
      "There was 96.83% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 125 and min_consecutives of: 45\n",
      "This data has 81 true events\n",
      "There were 5453 frames correctly classified, out of a total of 7076 frames classified as interaction.\n",
      "This results in an accuracy of 77.06%.\n",
      "There were a total of 63 events detected correctly, out of 86 total events detected. (73.26%)\n",
      "There was 77.78% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 125 and min_consecutives of: 45\n",
      "This data has 34 true events\n",
      "There were 2069 frames correctly classified, out of a total of 2130 frames classified as interaction.\n",
      "This results in an accuracy of 97.14%.\n",
      "There were a total of 17 events detected correctly, out of 18 total events detected. (94.44%)\n",
      "There was 50.00% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 125 and min_consecutives of: 45\n",
      "This data has 30 true events\n",
      "There were 5625 frames correctly classified, out of a total of 7232 frames classified as interaction.\n",
      "This results in an accuracy of 77.78%.\n",
      "There were a total of 27 events detected correctly, out of 40 total events detected. (67.50%)\n",
      "There was 90.00% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 125 and min_consecutives of: 45\n",
      "This data has 50 true events\n",
      "There were 4750 frames correctly classified, out of a total of 5588 frames classified as interaction.\n",
      "This results in an accuracy of 85.00%.\n",
      "There were a total of 43 events detected correctly, out of 58 total events detected. (74.14%)\n",
      "There was 86.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 125 and min_consecutives of: 60\n",
      "This data has 69 true events\n",
      "There were 5751 frames correctly classified, out of a total of 6282 frames classified as interaction.\n",
      "This results in an accuracy of 91.55%.\n",
      "There were a total of 40 events detected correctly, out of 46 total events detected. (86.96%)\n",
      "There was 57.97% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 125 and min_consecutives of: 60\n",
      "This data has 63 true events\n",
      "There were 7712 frames correctly classified, out of a total of 8502 frames classified as interaction.\n",
      "This results in an accuracy of 90.71%.\n",
      "There were a total of 47 events detected correctly, out of 57 total events detected. (82.46%)\n",
      "There was 74.60% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 125 and min_consecutives of: 60\n",
      "This data has 81 true events\n",
      "There were 3979 frames correctly classified, out of a total of 4872 frames classified as interaction.\n",
      "This results in an accuracy of 81.67%.\n",
      "There were a total of 41 events detected correctly, out of 51 total events detected. (80.39%)\n",
      "There was 50.62% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 125 and min_consecutives of: 60\n",
      "This data has 34 true events\n",
      "There were 1689 frames correctly classified, out of a total of 1750 frames classified as interaction.\n",
      "This results in an accuracy of 96.51%.\n",
      "There were a total of 11 events detected correctly, out of 12 total events detected. (91.67%)\n",
      "There was 32.35% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 125 and min_consecutives of: 60\n",
      "This data has 30 true events\n",
      "There were 5474 frames correctly classified, out of a total of 6876 frames classified as interaction.\n",
      "This results in an accuracy of 79.61%.\n",
      "There were a total of 25 events detected correctly, out of 34 total events detected. (73.53%)\n",
      "There was 83.33% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 125 and min_consecutives of: 60\n",
      "This data has 50 true events\n",
      "There were 4194 frames correctly classified, out of a total of 4435 frames classified as interaction.\n",
      "This results in an accuracy of 94.57%.\n",
      "There were a total of 35 events detected correctly, out of 38 total events detected. (92.11%)\n",
      "There was 70.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 150 and min_consecutives of: 30\n",
      "This data has 69 true events\n",
      "There were 9226 frames correctly classified, out of a total of 11462 frames classified as interaction.\n",
      "This results in an accuracy of 80.49%.\n",
      "There were a total of 71 events detected correctly, out of 109 total events detected. (65.14%)\n",
      "There was 102.90% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 150 and min_consecutives of: 30\n",
      "This data has 63 true events\n",
      "There were 10099 frames correctly classified, out of a total of 12201 frames classified as interaction.\n",
      "This results in an accuracy of 82.77%.\n",
      "There were a total of 71 events detected correctly, out of 109 total events detected. (65.14%)\n",
      "There was 112.70% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 150 and min_consecutives of: 30\n",
      "This data has 81 true events\n",
      "There were 9554 frames correctly classified, out of a total of 15437 frames classified as interaction.\n",
      "This results in an accuracy of 61.89%.\n",
      "There were a total of 97 events detected correctly, out of 203 total events detected. (47.78%)\n",
      "There was 119.75% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 150 and min_consecutives of: 30\n",
      "This data has 34 true events\n",
      "There were 2825 frames correctly classified, out of a total of 3109 frames classified as interaction.\n",
      "This results in an accuracy of 90.87%.\n",
      "There were a total of 26 events detected correctly, out of 33 total events detected. (78.79%)\n",
      "There was 76.47% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 150 and min_consecutives of: 30\n",
      "This data has 30 true events\n",
      "There were 6185 frames correctly classified, out of a total of 9820 frames classified as interaction.\n",
      "This results in an accuracy of 62.98%.\n",
      "There were a total of 31 events detected correctly, out of 51 total events detected. (60.78%)\n",
      "There was 103.33% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 150 and min_consecutives of: 30\n",
      "This data has 50 true events\n",
      "There were 6553 frames correctly classified, out of a total of 9491 frames classified as interaction.\n",
      "This results in an accuracy of 69.04%.\n",
      "There were a total of 53 events detected correctly, out of 110 total events detected. (48.18%)\n",
      "There was 106.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 150 and min_consecutives of: 45\n",
      "This data has 69 true events\n",
      "There were 8563 frames correctly classified, out of a total of 9727 frames classified as interaction.\n",
      "This results in an accuracy of 88.03%.\n",
      "There were a total of 60 events detected correctly, out of 74 total events detected. (81.08%)\n",
      "There was 86.96% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 150 and min_consecutives of: 45\n",
      "This data has 63 true events\n",
      "There were 9735 frames correctly classified, out of a total of 11104 frames classified as interaction.\n",
      "This results in an accuracy of 87.67%.\n",
      "There were a total of 63 events detected correctly, out of 81 total events detected. (77.78%)\n",
      "There was 100.00% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 150 and min_consecutives of: 45\n",
      "This data has 81 true events\n",
      "There were 8257 frames correctly classified, out of a total of 11993 frames classified as interaction.\n",
      "This results in an accuracy of 68.85%.\n",
      "There were a total of 75 events detected correctly, out of 126 total events detected. (59.52%)\n",
      "There was 92.59% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 150 and min_consecutives of: 45\n",
      "This data has 34 true events\n",
      "There were 2641 frames correctly classified, out of a total of 2710 frames classified as interaction.\n",
      "This results in an accuracy of 97.45%.\n",
      "There were a total of 21 events detected correctly, out of 22 total events detected. (95.45%)\n",
      "There was 61.76% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 150 and min_consecutives of: 45\n",
      "This data has 30 true events\n",
      "There were 6148 frames correctly classified, out of a total of 9391 frames classified as interaction.\n",
      "This results in an accuracy of 65.47%.\n",
      "There were a total of 30 events detected correctly, out of 43 total events detected. (69.77%)\n",
      "There was 100.00% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 150 and min_consecutives of: 45\n",
      "This data has 50 true events\n",
      "There were 6081 frames correctly classified, out of a total of 7828 frames classified as interaction.\n",
      "This results in an accuracy of 77.68%.\n",
      "There were a total of 46 events detected correctly, out of 71 total events detected. (64.79%)\n",
      "There was 92.00% events detected\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from: LD03 with threshold of: 150 and min_consecutives of: 60\n",
      "This data has 69 true events\n",
      "There were 8016 frames correctly classified, out of a total of 8917 frames classified as interaction.\n",
      "This results in an accuracy of 89.90%.\n",
      "There were a total of 53 events detected correctly, out of 63 total events detected. (84.13%)\n",
      "There was 76.81% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 150 and min_consecutives of: 60\n",
      "This data has 63 true events\n",
      "There were 9077 frames correctly classified, out of a total of 10192 frames classified as interaction.\n",
      "This results in an accuracy of 89.06%.\n",
      "There were a total of 54 events detected correctly, out of 67 total events detected. (80.60%)\n",
      "There was 85.71% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 150 and min_consecutives of: 60\n",
      "This data has 81 true events\n",
      "There were 7301 frames correctly classified, out of a total of 9763 frames classified as interaction.\n",
      "This results in an accuracy of 74.78%.\n",
      "There were a total of 65 events detected correctly, out of 92 total events detected. (70.65%)\n",
      "There was 80.25% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 150 and min_consecutives of: 60\n",
      "This data has 34 true events\n",
      "There were 2352 frames correctly classified, out of a total of 2421 frames classified as interaction.\n",
      "This results in an accuracy of 97.15%.\n",
      "There were a total of 17 events detected correctly, out of 18 total events detected. (94.44%)\n",
      "There was 50.00% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 150 and min_consecutives of: 60\n",
      "This data has 30 true events\n",
      "There were 5942 frames correctly classified, out of a total of 8965 frames classified as interaction.\n",
      "This results in an accuracy of 66.28%.\n",
      "There were a total of 26 events detected correctly, out of 37 total events detected. (70.27%)\n",
      "There was 86.67% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 150 and min_consecutives of: 60\n",
      "This data has 50 true events\n",
      "There were 5760 frames correctly classified, out of a total of 6847 frames classified as interaction.\n",
      "This results in an accuracy of 84.12%.\n",
      "There were a total of 40 events detected correctly, out of 54 total events detected. (74.07%)\n",
      "There was 80.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 175 and min_consecutives of: 30\n",
      "This data has 69 true events\n",
      "There were 10905 frames correctly classified, out of a total of 14565 frames classified as interaction.\n",
      "This results in an accuracy of 74.87%.\n",
      "There were a total of 63 events detected correctly, out of 125 total events detected. (50.40%)\n",
      "There was 91.30% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 175 and min_consecutives of: 30\n",
      "This data has 63 true events\n",
      "There were 11028 frames correctly classified, out of a total of 14200 frames classified as interaction.\n",
      "This results in an accuracy of 77.66%.\n",
      "There were a total of 68 events detected correctly, out of 118 total events detected. (57.63%)\n",
      "There was 107.94% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 175 and min_consecutives of: 30\n",
      "This data has 81 true events\n",
      "There were 12198 frames correctly classified, out of a total of 21027 frames classified as interaction.\n",
      "This results in an accuracy of 58.01%.\n",
      "There were a total of 106 events detected correctly, out of 240 total events detected. (44.17%)\n",
      "There was 130.86% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 175 and min_consecutives of: 30\n",
      "This data has 34 true events\n",
      "There were 3442 frames correctly classified, out of a total of 4079 frames classified as interaction.\n",
      "This results in an accuracy of 84.38%.\n",
      "There were a total of 28 events detected correctly, out of 44 total events detected. (63.64%)\n",
      "There was 82.35% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 175 and min_consecutives of: 30\n",
      "This data has 30 true events\n",
      "There were 6902 frames correctly classified, out of a total of 11127 frames classified as interaction.\n",
      "This results in an accuracy of 62.03%.\n",
      "There were a total of 29 events detected correctly, out of 48 total events detected. (60.42%)\n",
      "There was 96.67% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 175 and min_consecutives of: 30\n",
      "This data has 50 true events\n",
      "There were 8147 frames correctly classified, out of a total of 12776 frames classified as interaction.\n",
      "This results in an accuracy of 63.77%.\n",
      "There were a total of 50 events detected correctly, out of 132 total events detected. (37.88%)\n",
      "There was 100.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 175 and min_consecutives of: 45\n",
      "This data has 69 true events\n",
      "There were 10567 frames correctly classified, out of a total of 13007 frames classified as interaction.\n",
      "This results in an accuracy of 81.24%.\n",
      "There were a total of 62 events detected correctly, out of 92 total events detected. (67.39%)\n",
      "There was 89.86% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 175 and min_consecutives of: 45\n",
      "This data has 63 true events\n",
      "There were 10623 frames correctly classified, out of a total of 13049 frames classified as interaction.\n",
      "This results in an accuracy of 81.41%.\n",
      "There were a total of 64 events detected correctly, out of 93 total events detected. (68.82%)\n",
      "There was 101.59% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 175 and min_consecutives of: 45\n",
      "This data has 81 true events\n",
      "There were 11080 frames correctly classified, out of a total of 17868 frames classified as interaction.\n",
      "This results in an accuracy of 62.01%.\n",
      "There were a total of 90 events detected correctly, out of 174 total events detected. (51.72%)\n",
      "There was 111.11% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 175 and min_consecutives of: 45\n",
      "This data has 34 true events\n",
      "There were 3078 frames correctly classified, out of a total of 3246 frames classified as interaction.\n",
      "This results in an accuracy of 94.82%.\n",
      "There were a total of 24 events detected correctly, out of 27 total events detected. (88.89%)\n",
      "There was 70.59% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 175 and min_consecutives of: 45\n",
      "This data has 30 true events\n",
      "There were 6837 frames correctly classified, out of a total of 10683 frames classified as interaction.\n",
      "This results in an accuracy of 64.00%.\n",
      "There were a total of 27 events detected correctly, out of 39 total events detected. (69.23%)\n",
      "There was 90.00% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 175 and min_consecutives of: 45\n",
      "This data has 50 true events\n",
      "There were 7780 frames correctly classified, out of a total of 10917 frames classified as interaction.\n",
      "This results in an accuracy of 71.26%.\n",
      "There were a total of 46 events detected correctly, out of 91 total events detected. (50.55%)\n",
      "There was 92.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 175 and min_consecutives of: 60\n",
      "This data has 69 true events\n",
      "There were 9888 frames correctly classified, out of a total of 11549 frames classified as interaction.\n",
      "This results in an accuracy of 85.62%.\n",
      "There were a total of 55 events detected correctly, out of 72 total events detected. (76.39%)\n",
      "There was 79.71% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 175 and min_consecutives of: 60\n",
      "This data has 63 true events\n",
      "There were 10154 frames correctly classified, out of a total of 11812 frames classified as interaction.\n",
      "This results in an accuracy of 85.96%.\n",
      "There were a total of 58 events detected correctly, out of 77 total events detected. (75.32%)\n",
      "There was 92.06% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 175 and min_consecutives of: 60\n",
      "This data has 81 true events\n",
      "There were 9774 frames correctly classified, out of a total of 14148 frames classified as interaction.\n",
      "This results in an accuracy of 69.08%.\n",
      "There were a total of 71 events detected correctly, out of 116 total events detected. (61.21%)\n",
      "There was 87.65% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 175 and min_consecutives of: 60\n",
      "This data has 34 true events\n",
      "There were 2873 frames correctly classified, out of a total of 2947 frames classified as interaction.\n",
      "This results in an accuracy of 97.49%.\n",
      "There were a total of 20 events detected correctly, out of 21 total events detected. (95.24%)\n",
      "There was 58.82% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 175 and min_consecutives of: 60\n",
      "This data has 30 true events\n",
      "There were 6660 frames correctly classified, out of a total of 10124 frames classified as interaction.\n",
      "This results in an accuracy of 65.78%.\n",
      "There were a total of 25 events detected correctly, out of 32 total events detected. (78.12%)\n",
      "There was 83.33% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 175 and min_consecutives of: 60\n",
      "This data has 50 true events\n",
      "There were 7281 frames correctly classified, out of a total of 9094 frames classified as interaction.\n",
      "This results in an accuracy of 80.06%.\n",
      "There were a total of 40 events detected correctly, out of 62 total events detected. (64.52%)\n",
      "There was 80.00% events detected\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from: LD03 with threshold of: 200 and min_consecutives of: 30\n",
      "This data has 69 true events\n",
      "There were 11989 frames correctly classified, out of a total of 18121 frames classified as interaction.\n",
      "This results in an accuracy of 66.16%.\n",
      "There were a total of 65 events detected correctly, out of 151 total events detected. (43.05%)\n",
      "There was 94.20% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 200 and min_consecutives of: 30\n",
      "This data has 63 true events\n",
      "There were 11891 frames correctly classified, out of a total of 16383 frames classified as interaction.\n",
      "This results in an accuracy of 72.58%.\n",
      "There were a total of 67 events detected correctly, out of 141 total events detected. (47.52%)\n",
      "There was 106.35% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 200 and min_consecutives of: 30\n",
      "This data has 81 true events\n",
      "There were 14296 frames correctly classified, out of a total of 27527 frames classified as interaction.\n",
      "This results in an accuracy of 51.93%.\n",
      "There were a total of 102 events detected correctly, out of 279 total events detected. (36.56%)\n",
      "There was 125.93% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 200 and min_consecutives of: 30\n",
      "This data has 34 true events\n",
      "There were 4119 frames correctly classified, out of a total of 5058 frames classified as interaction.\n",
      "This results in an accuracy of 81.44%.\n",
      "There were a total of 31 events detected correctly, out of 53 total events detected. (58.49%)\n",
      "There was 91.18% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 200 and min_consecutives of: 30\n",
      "This data has 30 true events\n",
      "There were 6998 frames correctly classified, out of a total of 12222 frames classified as interaction.\n",
      "This results in an accuracy of 57.26%.\n",
      "There were a total of 28 events detected correctly, out of 50 total events detected. (56.00%)\n",
      "There was 93.33% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 200 and min_consecutives of: 30\n",
      "This data has 50 true events\n",
      "There were 9094 frames correctly classified, out of a total of 15927 frames classified as interaction.\n",
      "This results in an accuracy of 57.10%.\n",
      "There were a total of 48 events detected correctly, out of 151 total events detected. (31.79%)\n",
      "There was 96.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 200 and min_consecutives of: 45\n",
      "This data has 69 true events\n",
      "There were 11651 frames correctly classified, out of a total of 16011 frames classified as interaction.\n",
      "This results in an accuracy of 72.77%.\n",
      "There were a total of 62 events detected correctly, out of 114 total events detected. (54.39%)\n",
      "There was 89.86% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 200 and min_consecutives of: 45\n",
      "This data has 63 true events\n",
      "There were 11453 frames correctly classified, out of a total of 14638 frames classified as interaction.\n",
      "This results in an accuracy of 78.24%.\n",
      "There were a total of 65 events detected correctly, out of 104 total events detected. (62.50%)\n",
      "There was 103.17% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 200 and min_consecutives of: 45\n",
      "This data has 81 true events\n",
      "There were 13494 frames correctly classified, out of a total of 23813 frames classified as interaction.\n",
      "This results in an accuracy of 56.67%.\n",
      "There were a total of 87 events detected correctly, out of 206 total events detected. (42.23%)\n",
      "There was 107.41% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 200 and min_consecutives of: 45\n",
      "This data has 34 true events\n",
      "There were 3902 frames correctly classified, out of a total of 4358 frames classified as interaction.\n",
      "This results in an accuracy of 89.54%.\n",
      "There were a total of 28 events detected correctly, out of 36 total events detected. (77.78%)\n",
      "There was 82.35% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 200 and min_consecutives of: 45\n",
      "This data has 30 true events\n",
      "There were 7115 frames correctly classified, out of a total of 11868 frames classified as interaction.\n",
      "This results in an accuracy of 59.95%.\n",
      "There were a total of 27 events detected correctly, out of 45 total events detected. (60.00%)\n",
      "There was 90.00% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 200 and min_consecutives of: 45\n",
      "This data has 50 true events\n",
      "There were 8761 frames correctly classified, out of a total of 13825 frames classified as interaction.\n",
      "This results in an accuracy of 63.37%.\n",
      "There were a total of 44 events detected correctly, out of 106 total events detected. (41.51%)\n",
      "There was 88.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 200 and min_consecutives of: 60\n",
      "This data has 69 true events\n",
      "There were 11166 frames correctly classified, out of a total of 14016 frames classified as interaction.\n",
      "This results in an accuracy of 79.67%.\n",
      "There were a total of 57 events detected correctly, out of 85 total events detected. (67.06%)\n",
      "There was 82.61% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 200 and min_consecutives of: 60\n",
      "This data has 63 true events\n",
      "There were 11063 frames correctly classified, out of a total of 13695 frames classified as interaction.\n",
      "This results in an accuracy of 80.78%.\n",
      "There were a total of 60 events detected correctly, out of 88 total events detected. (68.18%)\n",
      "There was 95.24% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 200 and min_consecutives of: 60\n",
      "This data has 81 true events\n",
      "There were 12108 frames correctly classified, out of a total of 19830 frames classified as interaction.\n",
      "This results in an accuracy of 61.06%.\n",
      "There were a total of 74 events detected correctly, out of 147 total events detected. (50.34%)\n",
      "There was 91.36% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 200 and min_consecutives of: 60\n",
      "This data has 34 true events\n",
      "There were 3304 frames correctly classified, out of a total of 3461 frames classified as interaction.\n",
      "This results in an accuracy of 95.46%.\n",
      "There were a total of 22 events detected correctly, out of 24 total events detected. (91.67%)\n",
      "There was 64.71% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 200 and min_consecutives of: 60\n",
      "This data has 30 true events\n",
      "There were 7013 frames correctly classified, out of a total of 11211 frames classified as interaction.\n",
      "This results in an accuracy of 62.55%.\n",
      "There were a total of 25 events detected correctly, out of 36 total events detected. (69.44%)\n",
      "There was 83.33% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 200 and min_consecutives of: 60\n",
      "This data has 50 true events\n",
      "There were 8458 frames correctly classified, out of a total of 11740 frames classified as interaction.\n",
      "This results in an accuracy of 72.04%.\n",
      "There were a total of 40 events detected correctly, out of 72 total events detected. (55.56%)\n",
      "There was 80.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 225 and min_consecutives of: 30\n",
      "This data has 69 true events\n",
      "There were 12913 frames correctly classified, out of a total of 21418 frames classified as interaction.\n",
      "This results in an accuracy of 60.29%.\n",
      "There were a total of 64 events detected correctly, out of 176 total events detected. (36.36%)\n",
      "There was 92.75% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 225 and min_consecutives of: 30\n",
      "This data has 63 true events\n",
      "There were 12892 frames correctly classified, out of a total of 19047 frames classified as interaction.\n",
      "This results in an accuracy of 67.69%.\n",
      "There were a total of 65 events detected correctly, out of 163 total events detected. (39.88%)\n",
      "There was 103.17% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 225 and min_consecutives of: 30\n",
      "This data has 81 true events\n",
      "There were 15466 frames correctly classified, out of a total of 33592 frames classified as interaction.\n",
      "This results in an accuracy of 46.04%.\n",
      "There were a total of 94 events detected correctly, out of 298 total events detected. (31.54%)\n",
      "There was 116.05% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 225 and min_consecutives of: 30\n",
      "This data has 34 true events\n",
      "There were 4522 frames correctly classified, out of a total of 5990 frames classified as interaction.\n",
      "This results in an accuracy of 75.49%.\n",
      "There were a total of 33 events detected correctly, out of 63 total events detected. (52.38%)\n",
      "There was 97.06% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 225 and min_consecutives of: 30\n",
      "This data has 30 true events\n",
      "There were 7307 frames correctly classified, out of a total of 13400 frames classified as interaction.\n",
      "This results in an accuracy of 54.53%.\n",
      "There were a total of 25 events detected correctly, out of 48 total events detected. (52.08%)\n",
      "There was 83.33% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 225 and min_consecutives of: 30\n",
      "This data has 50 true events\n",
      "There were 9644 frames correctly classified, out of a total of 18194 frames classified as interaction.\n",
      "This results in an accuracy of 53.01%.\n",
      "There were a total of 45 events detected correctly, out of 157 total events detected. (28.66%)\n",
      "There was 90.00% events detected\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from: LD03 with threshold of: 225 and min_consecutives of: 45\n",
      "This data has 69 true events\n",
      "There were 12684 frames correctly classified, out of a total of 19275 frames classified as interaction.\n",
      "This results in an accuracy of 65.81%.\n",
      "There were a total of 64 events detected correctly, out of 135 total events detected. (47.41%)\n",
      "There was 92.75% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 225 and min_consecutives of: 45\n",
      "This data has 63 true events\n",
      "There were 12432 frames correctly classified, out of a total of 16680 frames classified as interaction.\n",
      "This results in an accuracy of 74.53%.\n",
      "There were a total of 63 events detected correctly, out of 116 total events detected. (54.31%)\n",
      "There was 100.00% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 225 and min_consecutives of: 45\n",
      "This data has 81 true events\n",
      "There were 15062 frames correctly classified, out of a total of 30233 frames classified as interaction.\n",
      "This results in an accuracy of 49.82%.\n",
      "There were a total of 86 events detected correctly, out of 226 total events detected. (38.05%)\n",
      "There was 106.17% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 225 and min_consecutives of: 45\n",
      "This data has 34 true events\n",
      "There were 4364 frames correctly classified, out of a total of 4983 frames classified as interaction.\n",
      "This results in an accuracy of 87.58%.\n",
      "There were a total of 30 events detected correctly, out of 40 total events detected. (75.00%)\n",
      "There was 88.24% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 225 and min_consecutives of: 45\n",
      "This data has 30 true events\n",
      "There were 7234 frames correctly classified, out of a total of 12933 frames classified as interaction.\n",
      "This results in an accuracy of 55.93%.\n",
      "There were a total of 24 events detected correctly, out of 40 total events detected. (60.00%)\n",
      "There was 80.00% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 225 and min_consecutives of: 45\n",
      "This data has 50 true events\n",
      "There were 9475 frames correctly classified, out of a total of 16707 frames classified as interaction.\n",
      "This results in an accuracy of 56.71%.\n",
      "There were a total of 43 events detected correctly, out of 127 total events detected. (33.86%)\n",
      "There was 86.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 225 and min_consecutives of: 60\n",
      "This data has 69 true events\n",
      "There were 12286 frames correctly classified, out of a total of 17603 frames classified as interaction.\n",
      "This results in an accuracy of 69.79%.\n",
      "There were a total of 59 events detected correctly, out of 110 total events detected. (53.64%)\n",
      "There was 85.51% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 225 and min_consecutives of: 60\n",
      "This data has 63 true events\n",
      "There were 12260 frames correctly classified, out of a total of 15595 frames classified as interaction.\n",
      "This results in an accuracy of 78.61%.\n",
      "There were a total of 61 events detected correctly, out of 96 total events detected. (63.54%)\n",
      "There was 96.83% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 225 and min_consecutives of: 60\n",
      "This data has 81 true events\n",
      "There were 14081 frames correctly classified, out of a total of 26005 frames classified as interaction.\n",
      "This results in an accuracy of 54.15%.\n",
      "There were a total of 76 events detected correctly, out of 173 total events detected. (43.93%)\n",
      "There was 93.83% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 225 and min_consecutives of: 60\n",
      "This data has 34 true events\n",
      "There were 3834 frames correctly classified, out of a total of 4138 frames classified as interaction.\n",
      "This results in an accuracy of 92.65%.\n",
      "There were a total of 24 events detected correctly, out of 28 total events detected. (85.71%)\n",
      "There was 70.59% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 225 and min_consecutives of: 60\n",
      "This data has 30 true events\n",
      "There were 7437 frames correctly classified, out of a total of 12368 frames classified as interaction.\n",
      "This results in an accuracy of 60.13%.\n",
      "There were a total of 24 events detected correctly, out of 35 total events detected. (68.57%)\n",
      "There was 80.00% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 225 and min_consecutives of: 60\n",
      "This data has 50 true events\n",
      "There were 8982 frames correctly classified, out of a total of 14373 frames classified as interaction.\n",
      "This results in an accuracy of 62.49%.\n",
      "There were a total of 37 events detected correctly, out of 91 total events detected. (40.66%)\n",
      "There was 74.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 250 and min_consecutives of: 30\n",
      "This data has 69 true events\n",
      "There were 13171 frames correctly classified, out of a total of 24598 frames classified as interaction.\n",
      "This results in an accuracy of 53.55%.\n",
      "There were a total of 65 events detected correctly, out of 198 total events detected. (32.83%)\n",
      "There was 94.20% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 250 and min_consecutives of: 30\n",
      "This data has 63 true events\n",
      "There were 13464 frames correctly classified, out of a total of 22252 frames classified as interaction.\n",
      "This results in an accuracy of 60.51%.\n",
      "There were a total of 64 events detected correctly, out of 197 total events detected. (32.49%)\n",
      "There was 101.59% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 250 and min_consecutives of: 30\n",
      "This data has 81 true events\n",
      "There were 17036 frames correctly classified, out of a total of 39609 frames classified as interaction.\n",
      "This results in an accuracy of 43.01%.\n",
      "There were a total of 89 events detected correctly, out of 308 total events detected. (28.90%)\n",
      "There was 109.88% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 250 and min_consecutives of: 30\n",
      "This data has 34 true events\n",
      "There were 4892 frames correctly classified, out of a total of 7363 frames classified as interaction.\n",
      "This results in an accuracy of 66.44%.\n",
      "There were a total of 31 events detected correctly, out of 84 total events detected. (36.90%)\n",
      "There was 91.18% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 250 and min_consecutives of: 30\n",
      "This data has 30 true events\n",
      "There were 7507 frames correctly classified, out of a total of 14460 frames classified as interaction.\n",
      "This results in an accuracy of 51.92%.\n",
      "There were a total of 25 events detected correctly, out of 50 total events detected. (50.00%)\n",
      "There was 83.33% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 250 and min_consecutives of: 30\n",
      "This data has 50 true events\n",
      "There were 10134 frames correctly classified, out of a total of 20602 frames classified as interaction.\n",
      "This results in an accuracy of 49.19%.\n",
      "There were a total of 42 events detected correctly, out of 164 total events detected. (25.61%)\n",
      "There was 84.00% events detected\n",
      "\n",
      "Data from: LD03 with threshold of: 250 and min_consecutives of: 45\n",
      "This data has 69 true events\n",
      "There were 12801 frames correctly classified, out of a total of 22042 frames classified as interaction.\n",
      "This results in an accuracy of 58.08%.\n",
      "There were a total of 62 events detected correctly, out of 149 total events detected. (41.61%)\n",
      "There was 89.86% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 250 and min_consecutives of: 45\n",
      "This data has 63 true events\n",
      "There were 13171 frames correctly classified, out of a total of 19309 frames classified as interaction.\n",
      "This results in an accuracy of 68.21%.\n",
      "There were a total of 64 events detected correctly, out of 137 total events detected. (46.72%)\n",
      "There was 101.59% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 250 and min_consecutives of: 45\n",
      "This data has 81 true events\n",
      "There were 16905 frames correctly classified, out of a total of 36531 frames classified as interaction.\n",
      "This results in an accuracy of 46.28%.\n",
      "There were a total of 87 events detected correctly, out of 255 total events detected. (34.12%)\n",
      "There was 107.41% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 250 and min_consecutives of: 45\n",
      "This data has 34 true events\n",
      "There were 4771 frames correctly classified, out of a total of 5991 frames classified as interaction.\n",
      "This results in an accuracy of 79.64%.\n",
      "There were a total of 29 events detected correctly, out of 49 total events detected. (59.18%)\n",
      "There was 85.29% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 250 and min_consecutives of: 45\n",
      "This data has 30 true events\n",
      "There were 7338 frames correctly classified, out of a total of 13948 frames classified as interaction.\n",
      "This results in an accuracy of 52.61%.\n",
      "There were a total of 23 events detected correctly, out of 43 total events detected. (53.49%)\n",
      "There was 76.67% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 250 and min_consecutives of: 45\n",
      "This data has 50 true events\n",
      "There were 10134 frames correctly classified, out of a total of 19372 frames classified as interaction.\n",
      "This results in an accuracy of 52.31%.\n",
      "There were a total of 42 events detected correctly, out of 140 total events detected. (30.00%)\n",
      "There was 84.00% events detected\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from: LD03 with threshold of: 250 and min_consecutives of: 60\n",
      "This data has 69 true events\n",
      "There were 12454 frames correctly classified, out of a total of 20312 frames classified as interaction.\n",
      "This results in an accuracy of 61.31%.\n",
      "There were a total of 61 events detected correctly, out of 126 total events detected. (48.41%)\n",
      "There was 88.41% events detected\n",
      "\n",
      "Data from: LD04 with threshold of: 250 and min_consecutives of: 60\n",
      "This data has 63 true events\n",
      "There were 12827 frames correctly classified, out of a total of 17192 frames classified as interaction.\n",
      "This results in an accuracy of 74.61%.\n",
      "There were a total of 62 events detected correctly, out of 104 total events detected. (59.62%)\n",
      "There was 98.41% events detected\n",
      "\n",
      "Data from: LD13 with threshold of: 250 and min_consecutives of: 60\n",
      "This data has 81 true events\n",
      "There were 15784 frames correctly classified, out of a total of 32406 frames classified as interaction.\n",
      "This results in an accuracy of 48.71%.\n",
      "There were a total of 75 events detected correctly, out of 196 total events detected. (38.27%)\n",
      "There was 92.59% events detected\n",
      "\n",
      "Data from: LD14 with threshold of: 250 and min_consecutives of: 60\n",
      "This data has 34 true events\n",
      "There were 4611 frames correctly classified, out of a total of 5112 frames classified as interaction.\n",
      "This results in an accuracy of 90.20%.\n",
      "There were a total of 26 events detected correctly, out of 32 total events detected. (81.25%)\n",
      "There was 76.47% events detected\n",
      "\n",
      "Data from: LD23 with threshold of: 250 and min_consecutives of: 60\n",
      "This data has 30 true events\n",
      "There were 7227 frames correctly classified, out of a total of 13627 frames classified as interaction.\n",
      "This results in an accuracy of 53.03%.\n",
      "There were a total of 22 events detected correctly, out of 39 total events detected. (56.41%)\n",
      "There was 73.33% events detected\n",
      "\n",
      "Data from: LD24 with threshold of: 250 and min_consecutives of: 60\n",
      "This data has 50 true events\n",
      "There were 9575 frames correctly classified, out of a total of 16915 frames classified as interaction.\n",
      "This results in an accuracy of 56.61%.\n",
      "There were a total of 39 events detected correctly, out of 104 total events detected. (37.50%)\n",
      "There was 78.00% events detected\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a list of threshold and min_consecutive values to test\n",
    "threshold_values = [100, 125, 150, 175, 200, 225, 250]  # Add more values if needed\n",
    "min_consecutive_values = [30, 45, 60]  # Add more values if needed\n",
    "\n",
    "\n",
    "for threshold in threshold_values:\n",
    "    for min_consecutive in min_consecutive_values:\n",
    "\n",
    "        summary_values = {}\n",
    "\n",
    "        for data_frame_name, data_frame in result_dataframes.items():\n",
    "            # Initialize variables to keep track of the current group\n",
    "            current_group = None\n",
    "            interaction_count = 0\n",
    "\n",
    "            # Iterate through the \"Behavior\" column\n",
    "            for behavior in data_frame[\"Behavior\"]:\n",
    "                if behavior == \"interaction\":\n",
    "                    if current_group != \"interaction\":\n",
    "                        # Start of a new interaction group\n",
    "                        interaction_count += 1\n",
    "                        current_group = \"interaction\"\n",
    "                else:\n",
    "                    current_group = None  # Reset the group if behavior is not \"interaction\"\n",
    "\n",
    "            summary_values[data_frame_name] = {\"true interaction count\": interaction_count}\n",
    "\n",
    "            \n",
    "            # Initialize the summary values with default values\n",
    "            summary_values[data_frame_name].update({\n",
    "                \"total_frames\": 0,\n",
    "                \"correctly_detected_event\": 0,\n",
    "                \"total\": 0,\n",
    "                \"correctly_frame_count\": 0\n",
    "            })\n",
    "            \n",
    "            # Reset the other summary values to zero to avoid overwriting\n",
    "            total_frames = 0\n",
    "            correctly_detected_event = 0\n",
    "            total = 0\n",
    "            correctly_frame_count = 0\n",
    "\n",
    "            interactions = detect_interactions(result_dataframes[data_frame_name][\"Min_Distance\"], min_consecutive, threshold)\n",
    "\n",
    "            for interaction in interactions:\n",
    "                start_frame, end_frame = interaction\n",
    "\n",
    "                if end_frame - start_frame + 1 >= 15:\n",
    "                    total += 1  # Increment the total count for eligible interactions\n",
    "                    total_frames += end_frame - start_frame + 1\n",
    "                    selected_data = result_dataframes[data_frame_name].loc[start_frame:end_frame, \"Behavior\"]\n",
    "                    #mode_value = stats.mode(selected_data).mode[0]\n",
    "                    mode_value = selected_data.mode().iloc[0]\n",
    "                    \n",
    "                    if mode_value == \"interaction\" or mode_value == \"TS\":\n",
    "                        correctly_detected_event += 1\n",
    "                        correctly_frame_count += end_frame - start_frame + 1\n",
    "\n",
    "                    # Store the prediction in the new column\n",
    "                    result_dataframes[data_frame_name].loc[start_frame:end_frame, \"Interaction_Predictions\"] = mode_value\n",
    "\n",
    "                # Update the existing summary values in the summary_values dictionary\n",
    "                summary_values[data_frame_name].update({\n",
    "                \"total_frames\": total_frames,\n",
    "                \"correctly_detected_event\": correctly_detected_event,\n",
    "                \"total\": total,\n",
    "                \"correctly_frame_count\": correctly_frame_count\n",
    "                })\n",
    "\n",
    "        #         if total == 1:\n",
    "        #             print(f\"\\nData from: {data_frame_name}\")\n",
    "        #         print(f\"Interaction detected from frame {start_frame} to {end_frame} (Duration: {end_frame - start_frame + 1} frames) with a true Behavior of {mode_value}\")\n",
    "\n",
    "        for data_frame, summary in summary_values.items():\n",
    "            true_interaction_count = summary['true interaction count']\n",
    "            total_frames = summary['total_frames']\n",
    "            correctly_frame_count = summary['correctly_frame_count']\n",
    "            total_detected_events = summary['total']\n",
    "            correctly_detected_events = summary['correctly_detected_event']\n",
    "\n",
    "            accuracy = (correctly_frame_count / total_frames) * 100 if total_frames != 0 else 0\n",
    "\n",
    "            print(f\"Data from: {data_frame} with threshold of: {threshold} and min_consecutives of: {min_consecutive}\")\n",
    "            print(f\"This data has {true_interaction_count} true events\")\n",
    "            print(f\"There were {correctly_frame_count} frames correctly classified, out of a total of {total_frames} frames classified as interaction.\")\n",
    "            print(f\"This results in an accuracy of {accuracy:.2f}%.\")\n",
    "            print(f\"There were a total of {correctly_detected_events} events detected correctly, out of {total_detected_events} total events detected. ({correctly_detected_events/total_detected_events *100:.2f}%)\" \n",
    "                 if total_detected_events != 0 else \"No events detected.\")\n",
    "            print(f\"There was {correctly_detected_events/true_interaction_count * 100:.2f}% events detected\")\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b706877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all {'LD03': 69, 'LD04': 63, 'LD13': 81, 'LD14': 34, 'LD23': 30, 'LD24': 50}\n",
      "+60 {'LD03': 64, 'LD04': 57, 'LD13': 67, 'LD14': 29, 'LD23': 25, 'LD24': 42}\n"
     ]
    }
   ],
   "source": [
    "interaction_counts = {}  # Create a dictionary to store interaction counts for each DataFrame\n",
    "\n",
    "for data_frame_name, data_frame in result_dataframes.items():\n",
    "    # Initialize variables to keep track of the current group\n",
    "    current_group = None\n",
    "    interaction_count = 0\n",
    "\n",
    "    # Iterate through the \"Behavior\" column\n",
    "    for behavior in data_frame[\"Behavior\"]:\n",
    "        if behavior == \"interaction\":\n",
    "            if current_group != \"interaction\":\n",
    "                # Start of a new interaction group\n",
    "                interaction_count += 1\n",
    "                current_group = \"interaction\"\n",
    "        else:\n",
    "            current_group = None  # Reset the group if behavior is not \"interaction\"\n",
    "\n",
    "    interaction_counts[data_frame_name] = interaction_count\n",
    "\n",
    "interaction_counts_60 = {}  # Create a dictionary to store interaction counts for each DataFrame\n",
    "\n",
    "for data_frame_name, data_frame in result_dataframes.items():\n",
    "    # Initialize variables to keep track of the current group\n",
    "    current_group = None\n",
    "    interaction_count = 0\n",
    "    current_group_count = 0\n",
    "\n",
    "    # Iterate through the \"Behavior\" column\n",
    "    for behavior in data_frame[\"Behavior\"]:\n",
    "        if behavior == \"interaction\":\n",
    "            if current_group != \"interaction\":\n",
    "                # Start of a new interaction group\n",
    "                current_group_count = 1\n",
    "                current_group = \"interaction\"\n",
    "            else:\n",
    "                current_group_count += 1\n",
    "        else:\n",
    "            if current_group_count >= 60:\n",
    "                interaction_count += 1\n",
    "            current_group = None  # Reset the group if behavior is not \"interaction\"\n",
    "            current_group_count = 0\n",
    "\n",
    "    # Check if the last group, if any, was an \"interaction\" group and met the condition\n",
    "    if current_group_count > 90:\n",
    "        interaction_count += 1\n",
    "\n",
    "    interaction_counts_60[data_frame_name] = interaction_count\n",
    "    \n",
    "print(\"all\",interaction_counts)\n",
    "print(\"+60\",interaction_counts_60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b5969",
   "metadata": {},
   "source": [
    "## Predicted Correct Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08a2d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame: LD03. With a total of: 69 events\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t56\t64\t71\t63\t65\t64\t65\n",
      "45\t40\t55\t60\t62\t62\t64\t62\n",
      "60\t29\t40\t53\t55\t57\t59\t61\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD04. With a total of: 63 events\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t65\t67\t71\t68\t67\t65\t64\n",
      "45\t55\t61\t63\t64\t65\t63\t64\n",
      "60\t38\t47\t54\t58\t60\t61\t62\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD13. With a total of: 81 events\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t62\t87\t97\t106\t102\t94\t89\n",
      "45\t34\t63\t75\t90\t87\t86\t87\n",
      "60\t18\t41\t65\t71\t74\t76\t75\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD14. With a total of: 34 events\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t15\t19\t26\t28\t31\t33\t31\n",
      "45\t10\t17\t21\t24\t28\t30\t29\n",
      "60\t7\t11\t17\t20\t22\t24\t26\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD23. With a total of: 30 events\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t35\t29\t31\t29\t28\t25\t25\n",
      "45\t30\t27\t30\t27\t27\t24\t23\n",
      "60\t22\t25\t26\t25\t25\t24\t22\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD24. With a total of: 50 events\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t44\t50\t53\t50\t48\t45\t42\n",
      "45\t32\t43\t46\t46\t44\t43\t42\n",
      "60\t26\t35\t40\t40\t40\t37\t39\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a list of threshold and min_consecutive values to test\n",
    "threshold_values = [100, 125, 150, 175, 200, 225, 250]  # Add more values if needed\n",
    "min_consecutive_values = [30, 45, 60]  # Add more values if needed\n",
    "\n",
    "# Iterate through all data frames\n",
    "for data_frame_name, data_frame in result_dataframes.items():\n",
    "    # Initialize a nested dictionary to store correctly detected events\n",
    "    correctly_detected_events = {}\n",
    "\n",
    "    # Loop through threshold and min_consecutive values\n",
    "    for threshold in threshold_values:\n",
    "        correctly_detected_events[threshold] = {}  # Initialize inner dictionary\n",
    "        for min_consecutive in min_consecutive_values:\n",
    "            summary_values = {}\n",
    "\n",
    "            # Initialize variables to keep track of the current group\n",
    "            current_group = None\n",
    "            interaction_count = 0\n",
    "\n",
    "            # Iterate through the \"Behavior\" column\n",
    "            for behavior in data_frame[\"Behavior\"]:\n",
    "                if behavior == \"interaction\":\n",
    "                    if current_group != \"interaction\":\n",
    "                        # Start of a new interaction group\n",
    "                        interaction_count += 1\n",
    "                        current_group = \"interaction\"\n",
    "                else:\n",
    "                    current_group = None  # Reset the group if behavior is not \"interaction\"\n",
    "\n",
    "            summary_values[data_frame_name] = {\"true interaction count\": interaction_count}\n",
    "\n",
    "            # Reset the other summary values to zero to avoid overwriting\n",
    "            total_frames = 0\n",
    "            correctly_detected_event = 0\n",
    "            total = 0\n",
    "            correctly_frame_count = 0\n",
    "\n",
    "            interactions = detect_interactions(data_frame[\"Min_Distance\"], min_consecutive, threshold)\n",
    "\n",
    "            for interaction in interactions:\n",
    "                start_frame, end_frame = interaction\n",
    "\n",
    "                if end_frame - start_frame + 1 >= 15:\n",
    "                    total += 1  # Increment the total count for eligible interactions\n",
    "                    total_frames += end_frame - start_frame + 1\n",
    "                    selected_data = data_frame.loc[start_frame:end_frame, \"Behavior\"]\n",
    "                    mode_value = selected_data.mode().iloc[0]\n",
    "\n",
    "                    if mode_value == \"interaction\" or mode_value == \"TS\":\n",
    "                        correctly_detected_event += 1\n",
    "                        correctly_frame_count += end_frame - start_frame + 1\n",
    "\n",
    "                    # Store the prediction in the new column\n",
    "                    data_frame.loc[start_frame:end_frame, \"Interaction_Predictions\"] = mode_value\n",
    "\n",
    "                # Update the existing summary values in the summary_values dictionary\n",
    "                summary_values[data_frame_name].update({\n",
    "                    \"total_frames\": total_frames,\n",
    "                    \"correctly_detected_event\": correctly_detected_event,\n",
    "                    \"total\": total,\n",
    "                    \"correctly_frame_count\": correctly_frame_count\n",
    "                })\n",
    "\n",
    "            correctly_detected_events[threshold][min_consecutive] = correctly_detected_event\n",
    "    print(f\"Data Frame: {data_frame_name}. With a total of: {interaction_count} events\")  # Add a header for the data frame\n",
    "    \n",
    "    # Now, display the table for the current data frame\n",
    "    print(\"\\t\" + \"\\t\".join(map(str, threshold_values)))  # Print column headers\n",
    "    for min_consecutive in min_consecutive_values:\n",
    "        row_values = [str(min_consecutive)]  # Start the row with min_consecutive value\n",
    "        for threshold in threshold_values:\n",
    "            cell_value = correctly_detected_events[threshold][min_consecutive]\n",
    "            row_values.append(str(cell_value))\n",
    "        print(\"\\t\".join(row_values))\n",
    "\n",
    "    # Add a line to separate data frames\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bcb252",
   "metadata": {},
   "source": [
    "## Number of wrong Events wrongly detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e009b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame: LD03\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t12\t21\t38\t62\t86\t112\t133\n",
      "45\t8\t10\t14\t30\t52\t71\t87\n",
      "60\t4\t6\t10\t17\t28\t51\t65\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD04\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t17\t27\t38\t50\t74\t98\t133\n",
      "45\t11\t11\t18\t29\t39\t53\t73\n",
      "60\t7\t10\t13\t19\t28\t35\t42\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD13\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t28\t62\t106\t134\t177\t204\t219\n",
      "45\t9\t23\t51\t84\t119\t140\t168\n",
      "60\t4\t10\t27\t45\t73\t97\t121\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD14\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t1\t3\t7\t16\t22\t30\t53\n",
      "45\t0\t1\t1\t3\t8\t10\t20\n",
      "60\t0\t1\t1\t1\t2\t4\t6\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD23\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t15\t20\t20\t19\t22\t23\t25\n",
      "45\t10\t13\t13\t12\t18\t16\t20\n",
      "60\t7\t9\t11\t7\t11\t11\t17\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD24\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t13\t27\t57\t82\t103\t112\t122\n",
      "45\t2\t15\t25\t45\t62\t84\t98\n",
      "60\t1\t3\t14\t22\t32\t54\t65\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a list of threshold and min_consecutive values to test\n",
    "threshold_values = [100, 125, 150, 175, 200, 225, 250]  # Add more values if needed\n",
    "min_consecutive_values = [30, 45, 60]  # Add more values if needed\n",
    "\n",
    "# Iterate through all data frames\n",
    "for data_frame_name, data_frame in result_dataframes.items():\n",
    "    print(f\"Data Frame: {data_frame_name}\")  # Add a header for the data frame\n",
    "\n",
    "    # Initialize a nested dictionary to store correctly detected events\n",
    "    correctly_detected_events = {}\n",
    "\n",
    "    # Loop through threshold and min_consecutive values\n",
    "    for threshold in threshold_values:\n",
    "        correctly_detected_events[threshold] = {}  # Initialize inner dictionary\n",
    "        for min_consecutive in min_consecutive_values:\n",
    "            summary_values = {}\n",
    "\n",
    "            # Initialize variables to keep track of the current group\n",
    "            current_group = None\n",
    "            interaction_count = 0\n",
    "\n",
    "            # Iterate through the \"Behavior\" column\n",
    "            for behavior in data_frame[\"Behavior\"]:\n",
    "                if behavior == \"interaction\":\n",
    "                    if current_group != \"interaction\":\n",
    "                        # Start of a new interaction group\n",
    "                        interaction_count += 1\n",
    "                        current_group = \"interaction\"\n",
    "                else:\n",
    "                    current_group = None  # Reset the group if behavior is not \"interaction\"\n",
    "\n",
    "            summary_values[data_frame_name] = {\"true interaction count\": interaction_count}\n",
    "            \n",
    "            # Initialize the summary values with default values\n",
    "            summary_values[data_frame_name].update({\n",
    "                \"total_frames\": 0,\n",
    "                \"correctly_detected_event\": 0,\n",
    "                \"total\": 0,\n",
    "                \"correctly_frame_count\": 0,\n",
    "                \"total_detected_events\": 0,\n",
    "                \"wrongly_detected_event\": 0\n",
    "            })\n",
    "\n",
    "            # Reset the other summary values to zero to avoid overwriting\n",
    "            total_frames = 0\n",
    "            correctly_detected_event = 0\n",
    "            total = 0\n",
    "            correctly_frame_count = 0\n",
    "            wrongly_detected_event = 0\n",
    "            wrongly_detected_frames = 0\n",
    "\n",
    "            interactions = detect_interactions(data_frame[\"Min_Distance\"], min_consecutive, threshold)\n",
    "\n",
    "            for interaction in interactions:\n",
    "                start_frame, end_frame = interaction\n",
    "\n",
    "                if end_frame - start_frame + 1 >= 15:\n",
    "                    total += 1  # Increment the total count for eligible interactions\n",
    "                    total_frames += end_frame - start_frame + 1\n",
    "                    selected_data = data_frame.loc[start_frame:end_frame, \"Behavior\"]\n",
    "                    mode_value = selected_data.mode().iloc[0]\n",
    "\n",
    "                    if mode_value == \"interaction\" or mode_value == \"TS\":\n",
    "                        correctly_detected_event += 1\n",
    "                        correctly_frame_count += end_frame - start_frame + 1\n",
    "                        \n",
    "                    else:\n",
    "                        wrongly_detected_event += 1\n",
    "                        wrongly_detected_frames += end_frame - start_frame + 1\n",
    "                        \n",
    "                    # Store the prediction in the new column\n",
    "                    data_frame.loc[start_frame:end_frame, \"Interaction_Predictions\"] = mode_value\n",
    "\n",
    "                # Update the existing summary values in the summary_values dictionary\n",
    "                summary_values[data_frame_name].update({\n",
    "                    \"total_frames\": total_frames,\n",
    "                    \"correctly_detected_event\": correctly_detected_event,\n",
    "                    \"total_detected_events\": total,\n",
    "                    \"correctly_frame_count\": correctly_frame_count,\n",
    "                    \"wrongly_detected_event\": wrongly_detected_event,\n",
    "                    \"wrongly_detected_frames\": wrongly_detected_frames\n",
    "                })\n",
    "\n",
    "            correctly_detected_events[threshold][min_consecutive] = summary_values[data_frame_name][\"wrongly_detected_event\"]  # Calculate and store the ratio\n",
    "\n",
    "    # Now, display the table for the current data frame\n",
    "    print(\"\\t\" + \"\\t\".join(map(str, threshold_values)))  # Print column headers\n",
    "    for min_consecutive in min_consecutive_values:\n",
    "        row_values = [str(min_consecutive)]  # Start the row with min_consecutive value\n",
    "        for threshold in threshold_values:\n",
    "            cell_value = correctly_detected_events[threshold][min_consecutive]\n",
    "            row_values.append(f\"{cell_value}\")  # Format as percentage\n",
    "        print(\"\\t\".join(row_values))\n",
    "\n",
    "    # Add a line to separate data frames\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f8844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce8fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb39b79",
   "metadata": {},
   "source": [
    "## Number of correct frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "784600a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame: LD03. With a total of: 13729 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t5281\t7251\t9226\t10905\t11989\t12913\t13171\n",
      "45\t4492\t6708\t8563\t10567\t11651\t12684\t12801\n",
      "60\t3745\t5751\t8016\t9888\t11166\t12286\t12454\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD04. With a total of: 15986 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t7625\t9030\t10099\t11028\t11891\t12892\t13464\n",
      "45\t7001\t8500\t9735\t10623\t11453\t12432\t13171\n",
      "60\t6069\t7712\t9077\t10154\t11063\t12260\t12827\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD13. With a total of: 20744 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t3849\t6626\t9554\t12198\t14296\t15466\t17036\n",
      "45\t2388\t5453\t8257\t11080\t13494\t15062\t16905\n",
      "60\t1533\t3979\t7301\t9774\t12108\t14081\t15784\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD14. With a total of: 5423 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t1397\t2196\t2825\t3442\t4119\t4522\t4892\n",
      "45\t1218\t2069\t2641\t3078\t3902\t4364\t4771\n",
      "60\t1061\t1689\t2352\t2873\t3304\t3834\t4611\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD23. With a total of: 8044 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t4668\t5713\t6185\t6902\t6998\t7307\t7507\n",
      "45\t4186\t5625\t6148\t6837\t7115\t7234\t7338\n",
      "60\t3425\t5474\t5942\t6660\t7013\t7437\t7227\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD24. With a total of: 9741 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t3669\t5164\t6553\t8147\t9094\t9644\t10134\n",
      "45\t3102\t4750\t6081\t7780\t8761\t9475\t10134\n",
      "60\t2776\t4194\t5760\t7281\t8458\t8982\t9575\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a list of threshold and min_consecutive values to test\n",
    "threshold_values = [100, 125, 150, 175, 200, 225, 250]  # Add more values if needed\n",
    "min_consecutive_values = [30, 45, 60]  # Add more values if needed\n",
    "\n",
    "# Iterate through all data frames\n",
    "for data_frame_name, data_frame in result_dataframes.items():\n",
    "    # Initialize a nested dictionary to store correctly detected frames\n",
    "    correctly_detected_frames = {}\n",
    "\n",
    "    # Loop through threshold and min_consecutive values\n",
    "    for threshold in threshold_values:\n",
    "        correctly_detected_frames[threshold] = {}  # Initialize inner dictionary\n",
    "        for min_consecutive in min_consecutive_values:\n",
    "            summary_values = {}\n",
    "\n",
    "            # Initialize variables to keep track of the current group\n",
    "            current_group = None\n",
    "            interaction_count = 0\n",
    "\n",
    "            # Iterate through the \"Behavior\" column\n",
    "            for behavior in data_frame[\"Behavior\"]:\n",
    "                if behavior == \"interaction\":\n",
    "                    if current_group != \"interaction\":\n",
    "                        # Start of a new interaction group\n",
    "                        interaction_count += 1\n",
    "                        current_group = \"interaction\"\n",
    "                else:\n",
    "                    current_group = None  # Reset the group if behavior is not \"interaction\"\n",
    "\n",
    "            summary_values[data_frame_name] = {\"true interaction count\": interaction_count}\n",
    "\n",
    "            # Reset the other summary values to zero to avoid overwriting\n",
    "            total_frames = 0\n",
    "            correctly_detected_frames_count = 0  # Updated variable name\n",
    "            total = 0\n",
    "            correctly_frame_count = 0\n",
    "\n",
    "            interactions = detect_interactions(data_frame[\"Min_Distance\"], min_consecutive, threshold)\n",
    "\n",
    "            for interaction in interactions:\n",
    "                start_frame, end_frame = interaction\n",
    "\n",
    "                if end_frame - start_frame + 1 >= 15:\n",
    "                    total += 1  # Increment the total count for eligible interactions\n",
    "                    total_frames += end_frame - start_frame + 1\n",
    "                    selected_data = data_frame.loc[start_frame:end_frame, \"Behavior\"]\n",
    "                    mode_value = selected_data.mode().iloc[0]\n",
    "\n",
    "                    if mode_value == \"interaction\" or mode_value == \"TS\":\n",
    "                        correctly_detected_frames_count += end_frame - start_frame + 1  # Updated variable name\n",
    "\n",
    "                    # Store the prediction in the new column\n",
    "                    data_frame.loc[start_frame:end_frame, \"Interaction_Predictions\"] = mode_value\n",
    "\n",
    "                # Update the existing summary values in the summary_values dictionary\n",
    "                summary_values[data_frame_name].update({\n",
    "                    \"total_frames\": total_frames,\n",
    "                    \"correctly_detected_frames_count\": correctly_detected_frames_count,  # Updated variable name\n",
    "                    \"total\": total,\n",
    "                    \"correctly_frame_count\": correctly_frame_count\n",
    "                })\n",
    "\n",
    "            correctly_detected_frames[threshold][min_consecutive] = correctly_detected_frames_count  # Updated variable name\n",
    "    print(f\"Data Frame: {data_frame_name}. With a total of: {data_frame['Behavior'].value_counts().get('interaction', 0)} frames\")  # Add a header for the data frame\n",
    "\n",
    "    # Now, display the table for the current data frame\n",
    "    print(\"\\t\" + \"\\t\".join(map(str, threshold_values)))  # Print column headers\n",
    "    for min_consecutive in min_consecutive_values:\n",
    "        row_values = [str(min_consecutive)]  # Start the row with min_consecutive value\n",
    "        for threshold in threshold_values:\n",
    "            cell_value = correctly_detected_frames[threshold][min_consecutive]  # Updated variable name\n",
    "            row_values.append(str(cell_value))\n",
    "        print(\"\\t\".join(row_values))\n",
    "\n",
    "    # Add a line to separate data frames\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5dba6a",
   "metadata": {},
   "source": [
    "## Number of wrong frames predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1e90d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame: LD03. With a total of: 13729 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t695\t1193\t2236\t3660\t6132\t8505\t11427\n",
      "45\t534\t733\t1164\t2440\t4360\t6591\t9241\n",
      "60\t336\t531\t901\t1661\t2850\t5317\t7858\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD04. With a total of: 15986 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t954\t1389\t2102\t3172\t4492\t6155\t8788\n",
      "45\t750\t835\t1369\t2426\t3185\t4248\t6138\n",
      "60\t534\t790\t1115\t1658\t2632\t3335\t4365\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD13. With a total of: 20744 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t1272\t3070\t5883\t8829\t13231\t18126\t22573\n",
      "45\t521\t1623\t3736\t6788\t10319\t15171\t19626\n",
      "60\t281\t893\t2462\t4374\t7722\t11924\t16622\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD14. With a total of: 5423 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t40\t129\t284\t637\t939\t1468\t2471\n",
      "45\t0\t61\t69\t168\t456\t619\t1220\n",
      "60\t0\t61\t69\t74\t157\t304\t501\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD23. With a total of: 8044 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t1167\t2000\t3635\t4225\t5224\t6093\t6953\n",
      "45\t962\t1607\t3243\t3846\t4753\t5699\t6610\n",
      "60\t792\t1402\t3023\t3464\t4198\t4931\t6400\n",
      "------------------------------------------------------------\n",
      "Data Frame: LD24. With a total of: 9741 frames\n",
      "\t100\t125\t150\t175\t200\t225\t250\n",
      "30\t508\t1267\t2938\t4629\t6833\t8550\t10468\n",
      "45\t116\t838\t1747\t3137\t5064\t7232\t9238\n",
      "60\t71\t241\t1087\t1813\t3282\t5391\t7340\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a list of threshold and min_consecutive values to test\n",
    "threshold_values = [100, 125, 150, 175, 200, 225, 250]  # Add more values if needed\n",
    "min_consecutive_values = [30, 45, 60]  # Add more values if needed\n",
    "\n",
    "# Iterate through all data frames\n",
    "for data_frame_name, data_frame in result_dataframes.items():\n",
    "    # Initialize a nested dictionary to store incorrectly detected frames\n",
    "    incorrectly_detected_frames = {}\n",
    "\n",
    "    # Loop through threshold and min_consecutive values\n",
    "    for threshold in threshold_values:\n",
    "        incorrectly_detected_frames[threshold] = {}  # Initialize inner dictionary\n",
    "        for min_consecutive in min_consecutive_values:\n",
    "            summary_values = {}\n",
    "\n",
    "            # Initialize variables to keep track of the current group\n",
    "            current_group = None\n",
    "            interaction_count = 0\n",
    "\n",
    "            # Iterate through the \"Behavior\" column\n",
    "            for behavior in data_frame[\"Behavior\"]:\n",
    "                if behavior == \"interaction\":\n",
    "                    if current_group != \"interaction\":\n",
    "                        # Start of a new interaction group\n",
    "                        interaction_count += 1\n",
    "                        current_group = \"interaction\"\n",
    "                else:\n",
    "                    current_group = None  # Reset the group if behavior is not \"interaction\"\n",
    "\n",
    "            summary_values[data_frame_name] = {\"true interaction count\": interaction_count}\n",
    "\n",
    "            # Reset the other summary values to zero to avoid overwriting\n",
    "            total_frames = 0\n",
    "            correctly_detected_frames_count = 0\n",
    "            incorrectly_detected_frames_count = 0  # Updated variable name\n",
    "            total = 0\n",
    "            correctly_frame_count = 0\n",
    "\n",
    "            interactions = detect_interactions(data_frame[\"Min_Distance\"], min_consecutive, threshold)\n",
    "\n",
    "            for interaction in interactions:\n",
    "                start_frame, end_frame = interaction\n",
    "\n",
    "                if end_frame - start_frame + 1 >= 15:\n",
    "                    total += 1  # Increment the total count for eligible interactions\n",
    "                    total_frames += end_frame - start_frame + 1\n",
    "                    selected_data = data_frame.loc[start_frame:end_frame, \"Behavior\"]\n",
    "                    mode_value = selected_data.mode().iloc[0]\n",
    "\n",
    "                    if mode_value == \"interaction\" or mode_value == \"TS\":\n",
    "                        correctly_detected_frames_count += end_frame - start_frame + 1\n",
    "                    else:\n",
    "                        incorrectly_detected_frames_count += end_frame - start_frame + 1\n",
    "\n",
    "                    # Store the prediction in the new column\n",
    "                    data_frame.loc[start_frame:end_frame, \"Interaction_Predictions\"] = mode_value\n",
    "\n",
    "                # Update the existing summary values in the summary_values dictionary\n",
    "                summary_values[data_frame_name].update({\n",
    "                    \"total_frames\": total_frames,\n",
    "                    \"correctly_detected_frames_count\": correctly_detected_frames_count,\n",
    "                    \"incorrectly_detected_frames_count\": incorrectly_detected_frames_count,  # Updated variable name\n",
    "                    \"total\": total,\n",
    "                    \"correctly_frame_count\": correctly_frame_count\n",
    "                })\n",
    "\n",
    "            incorrectly_detected_frames[threshold][min_consecutive] = incorrectly_detected_frames_count  # Updated variable name\n",
    "    print(f\"Data Frame: {data_frame_name}. With a total of: {data_frame['Behavior'].value_counts().get('interaction', 0)} frames\")  # Add a header for the data frame\n",
    "\n",
    "    # Now, display the table for the current data frame\n",
    "    print(\"\\t\" + \"\\t\".join(map(str, threshold_values)))  # Print column headers\n",
    "    for min_consecutive in min_consecutive_values:\n",
    "        row_values = [str(min_consecutive)]  # Start the row with min_consecutive value\n",
    "        for threshold in threshold_values:\n",
    "            cell_value = incorrectly_detected_frames[threshold][min_consecutive]  # Updated variable name\n",
    "            row_values.append(str(cell_value))\n",
    "        print(\"\\t\".join(row_values))\n",
    "\n",
    "    # Add a line to separate data frames\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7cfa61",
   "metadata": {},
   "source": [
    "#### Creates a dict with predicted | true labels for all dataframes with all param combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f655f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of threshold and min_consecutive values to test\n",
    "threshold_values = [100, 125, 150, 175, 200, 225, 250]\n",
    "min_consecutive_values = [30, 45, 60]\n",
    "\n",
    "# Initialize a dictionary to store results for each combination\n",
    "results_dict = {}\n",
    "\n",
    "# Iterate through all data frames\n",
    "for data_frame_name, data_frame in result_dataframes.items():\n",
    "    # Initialize a nested dictionary for the current data frame\n",
    "    data_frame_results = {}\n",
    "\n",
    "    # Loop through threshold and min_consecutive values\n",
    "    for threshold in threshold_values:\n",
    "        for min_consecutive in min_consecutive_values:\n",
    "            interactions = detect_interactions(data_frame[\"Min_Distance\"], min_consecutive, threshold)\n",
    "\n",
    "            # Initialize an empty DataFrame to store \"Behavior\" and \"Interaction_Predictions\" columns\n",
    "            selected_data = pd.DataFrame(columns=[\"Behavior\", \"Interaction_Predictions\"])\n",
    "            selected_data[\"Behavior\"] = data_frame[\"Behavior\"]\n",
    "            selected_data[\"Interaction_Predictions\"] = \"background\"\n",
    "\n",
    "            for interaction in interactions:\n",
    "                start_frame, end_frame = interaction\n",
    "\n",
    "                if end_frame - start_frame + 1 >= 15:\n",
    "                    selected_data.loc[start_frame:end_frame, \"Interaction_Predictions\"] = \"interaction\"\n",
    "\n",
    "            # Store the selected data in the data frame results\n",
    "            data_frame_results[(threshold, min_consecutive)] = selected_data\n",
    "\n",
    "    # Store the data frame results in the overall results dictionary\n",
    "    results_dict[data_frame_name] = data_frame_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff71c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder where you want to save the CSV files\n",
    "output_folder = r\"C:\\Users\\raulo\\Desktop\\ze_vids\\phase_3\\results_dataframes\\CleanerCentroid2_ClientAll_smaller_margin\"\n",
    "\n",
    "# Save the results to CSV files\n",
    "for data_frame_name, data_frame_results in results_dict.items():\n",
    "    for (threshold, min_consecutive), selected_data in data_frame_results.items():\n",
    "        # Generate a filename based on the data frame name, threshold, and min_consecutive values\n",
    "        filename = f\"{data_frame_name}_threshold{threshold}_minc{min_consecutive}.csv\"\n",
    "\n",
    "        # Create the full path by joining the output folder and filename\n",
    "        full_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Save the selected data to CSV\n",
    "        selected_data.to_csv(full_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966f19b",
   "metadata": {},
   "source": [
    "#### Creates plots with predicted | true horizontal histograms with 1000 frames each where it saves the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e82c4fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# # Define the main output directory where you want to save the plots\n",
    "# main_output_directory = r\"C:\\Users\\raulo\\Desktop\\ze_vids\\phase_3\\Plots\\smaller_distance-client-points_ALL_cleaner2points_W-Margin\"\n",
    "\n",
    "# # Create the main output directory if it doesn't exist\n",
    "# os.makedirs(main_output_directory, exist_ok=True)\n",
    "\n",
    "# # Iterate through data frames and their results\n",
    "# for data_frame_name, data_frame_results in results_dict.items():\n",
    "#     # Create a subdirectory for the current data frame within the main output directory\n",
    "#     data_frame_directory = os.path.join(main_output_directory, data_frame_name)\n",
    "#     os.makedirs(data_frame_directory, exist_ok=True)\n",
    "\n",
    "#     for (threshold, min_consecutive), selected_data in data_frame_results.items():\n",
    "#         # Create a subdirectory for the current parameter combination within the data frame directory\n",
    "#         parameter_directory = os.path.join(data_frame_directory, f\"T{threshold}_MC{min_consecutive}\")\n",
    "#         os.makedirs(parameter_directory, exist_ok=True)\n",
    "\n",
    "#         # Define the true and predicted labels\n",
    "#         true_labels = selected_data[\"Behavior\"]\n",
    "#         predicted_labels = selected_data[\"Interaction_Predictions\"]\n",
    "\n",
    "#         # Define the size of each chunk\n",
    "#         chunk_size = 5000\n",
    "\n",
    "#         # Calculate the number of chunks\n",
    "#         num_chunks = len(true_labels) // chunk_size\n",
    "\n",
    "#         for chunk in range(num_chunks):\n",
    "#             start_frame = chunk * chunk_size\n",
    "#             end_frame = start_frame + chunk_size\n",
    "\n",
    "#             # Create a figure and axes for each chunk\n",
    "#             fig, ax = plt.subplots()\n",
    "\n",
    "#             # Create a horizontal bar for true labels\n",
    "#             for frame, label in enumerate(true_labels[start_frame:end_frame]):\n",
    "#                 color = 'blue' if label == \"interaction\" else 'gray'\n",
    "#                 ax.barh(0, 1, left=frame + start_frame, color=color)\n",
    "\n",
    "#             # Create a horizontal bar for predicted labels (below)\n",
    "#             for frame, label in enumerate(predicted_labels[start_frame:end_frame]):\n",
    "#                 color = 'blue' if label == \"interaction\" else 'gray'\n",
    "#                 ax.barh(1, 1, left=frame + start_frame, color=color)\n",
    "\n",
    "#             # Customize the plot\n",
    "#             ax.set_yticks([0, 1])\n",
    "#             ax.set_yticklabels([\"True\", \"Predicted\"])\n",
    "#             ax.set_xlabel('Frame Number')\n",
    "#             ax.set_xlim(start_frame, end_frame)\n",
    "#             ax.set_ylim(-1, 2)\n",
    "\n",
    "#             # Save the plot as an image in the parameter-specific subdirectory\n",
    "#             output_file = os.path.join(parameter_directory, f\"chunk{chunk}.png\")\n",
    "#             plt.savefig(output_file)\n",
    "#             #plt.show()\n",
    "#             # Close the current plot\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "#             gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
